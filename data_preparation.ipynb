{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import interpolation as inter\n",
    "from PIL import Image as im\n",
    "import re\n",
    "# from segmentation.utilities import projection, save_image\n",
    "# from segmentation.preprocessing import binary_otsus, deskew\n",
    "from segmentation.segmentation import line_horizontal_projection, word_vertical_projection\n",
    "from segmentation.character_segmentation import segment\n",
    "from tensorflow.keras.models import load_model\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "from Preprocessing.preprocessing import otsu_threshold, crop_on_borders\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Segment(img):\n",
    "\n",
    "    words_chars = []\n",
    "    lines = line_horizontal_projection(img)\n",
    "    for line in lines:\n",
    "        words = word_vertical_projection(line)\n",
    "        for word in words :\n",
    "            cr = segment(line, word)\n",
    "            words_chars.append(cr)\n",
    "\n",
    "    return words_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    img = cv.imread(path)  # Read the image\n",
    "    if img is not None:\n",
    "        return img  # Return the image array if successfully read\n",
    "    else:\n",
    "        print(f\"Error reading image: {path}\")\n",
    "        return None  # Return None for failed reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\\img_1.png\n",
      "Dataset\\img_10.png\n",
      "Dataset\\img_2.png\n",
      "Dataset\\img_3.png\n",
      "Dataset\\img_4.png\n",
      "Dataset\\img_5.png\n",
      "Dataset\\img_6.png\n",
      "Dataset\\img_7.png\n",
      "Dataset\\img_8.png\n",
      "Dataset\\img_9.png\n"
     ]
    }
   ],
   "source": [
    "main_path = 'Dataset'\n",
    "output_path = \"Data\"\n",
    "images = os.listdir(main_path)\n",
    "i = 1\n",
    "for img in images :\n",
    "    img_path = os.path.join(main_path, img)\n",
    "    print(img_path)\n",
    "    image = read_image(img_path)\n",
    "    words_ch = Segment(image)\n",
    "    for ch in words_ch :\n",
    "        for c in ch :\n",
    "            imge = Image.fromarray(c)\n",
    "            imge.save(f\"Data/img_{i}.png\", format=\"PNG\")\n",
    "            i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # img = preprocess(image_path)\n",
    "# img = read_image(image_path)\n",
    "# words_ch = Segment(img)\n",
    "# text = ''\n",
    "# for ch in words_ch:\n",
    "#     word = ''\n",
    "#     for c in ch :\n",
    "#         img = Image.fromarray(c)\n",
    "#         crop_pars = crop_on_borders(img)\n",
    "#         cropped = np.array(img.crop(crop_pars).resize((60,60)).convert(\"L\"))\n",
    "#         temp = np.array([cropped])\n",
    "#         res = model.predict(temp)\n",
    "#         char = chars[np.argmax(res)]\n",
    "#         word += char\n",
    "#         print(char)\n",
    "#     text += word + ' '\n",
    "# print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
